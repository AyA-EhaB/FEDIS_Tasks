{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "363b08c7",
   "metadata": {
    "papermill": {
     "duration": 0.003515,
     "end_time": "2025-08-24T02:41:48.762385",
     "exception": false,
     "start_time": "2025-08-24T02:41:48.758870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- AlexNet (2012): First breakthrough CNN. Shallow (8 layers), fast, weaker accuracy by today’s standards.\n",
    "\n",
    "- ResNet152 (2015): Very deep (152 layers), uses skip connections so it can train without vanishing gradients. Much more accurate, but heavier and slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7278da15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T02:41:48.768799Z",
     "iopub.status.busy": "2025-08-24T02:41:48.768579Z",
     "iopub.status.idle": "2025-08-24T02:42:03.213764Z",
     "shell.execute_reply": "2025-08-24T02:42:03.213197Z"
    },
    "papermill": {
     "duration": 14.449793,
     "end_time": "2025-08-24T02:42:03.215111",
     "exception": false,
     "start_time": "2025-08-24T02:41:48.765318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4660147b",
   "metadata": {
    "papermill": {
     "duration": 0.00251,
     "end_time": "2025-08-24T02:42:03.220657",
     "exception": false,
     "start_time": "2025-08-24T02:42:03.218147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing (Transforms)\n",
    "### Pretrained models expect images:\n",
    "##### - size: 224x224\n",
    "##### - normalized using ImageNet's mean & std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13704cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T02:42:03.226782Z",
     "iopub.status.busy": "2025-08-24T02:42:03.226480Z",
     "iopub.status.idle": "2025-08-24T02:42:03.230530Z",
     "shell.execute_reply": "2025-08-24T02:42:03.229978Z"
    },
    "papermill": {
     "duration": 0.008294,
     "end_time": "2025-08-24T02:42:03.231539",
     "exception": false,
     "start_time": "2025-08-24T02:42:03.223245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233f01b",
   "metadata": {
    "papermill": {
     "duration": 0.002292,
     "end_time": "2025-08-24T02:42:03.236533",
     "exception": false,
     "start_time": "2025-08-24T02:42:03.234241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**'transforms.ToTensor()'**\n",
    "\n",
    "What does it do?\n",
    "- PyTorch expects images as tensors in a specific format:\n",
    "\n",
    "- Channels first → (C, H, W)\n",
    "\n",
    "- C = channels (3 for RGB), H = height, W = width\n",
    "\n",
    "- But most image libraries (like PIL, OpenCV, NumPy) store them as:\n",
    "\n",
    "- Channels last → (H, W, C)\n",
    "\n",
    "- 👉 transforms.ToTensor() changes the order from (H, W, C) to (C, H, W)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce94960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T02:42:03.242366Z",
     "iopub.status.busy": "2025-08-24T02:42:03.242151Z",
     "iopub.status.idle": "2025-08-24T02:42:07.872709Z",
     "shell.execute_reply": "2025-08-24T02:42:07.872062Z"
    },
    "papermill": {
     "duration": 4.635142,
     "end_time": "2025-08-24T02:42:07.874133",
     "exception": false,
     "start_time": "2025-08-24T02:42:03.238991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:01<00:00, 85.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root = './data', train = True, download = True,\n",
    "    transform = transform \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f9ab49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T02:42:07.883139Z",
     "iopub.status.busy": "2025-08-24T02:42:07.882487Z",
     "iopub.status.idle": "2025-08-24T02:42:07.886501Z",
     "shell.execute_reply": "2025-08-24T02:42:07.885773Z"
    },
    "papermill": {
     "duration": 0.009151,
     "end_time": "2025-08-24T02:42:07.887537",
     "exception": false,
     "start_time": "2025-08-24T02:42:07.878386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainloader  =torch.utils.data.DataLoader(trainset, batch_size = 32,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a8b474f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T02:42:07.895274Z",
     "iopub.status.busy": "2025-08-24T02:42:07.895053Z",
     "iopub.status.idle": "2025-08-24T02:42:08.582097Z",
     "shell.execute_reply": "2025-08-24T02:42:08.581319Z"
    },
    "papermill": {
     "duration": 0.692404,
     "end_time": "2025-08-24T02:42:08.583491",
     "exception": false,
     "start_time": "2025-08-24T02:42:07.891087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True,\n",
    "    transform = transform )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31aaf3f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T02:42:08.592695Z",
     "iopub.status.busy": "2025-08-24T02:42:08.592055Z",
     "iopub.status.idle": "2025-08-24T02:42:08.595661Z",
     "shell.execute_reply": "2025-08-24T02:42:08.595158Z"
    },
    "papermill": {
     "duration": 0.009103,
     "end_time": "2025-08-24T02:42:08.596630",
     "exception": false,
     "start_time": "2025-08-24T02:42:08.587527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testloader  =torch.utils.data.DataLoader(testset, batch_size = 32,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d966bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T02:42:08.604893Z",
     "iopub.status.busy": "2025-08-24T02:42:08.604701Z",
     "iopub.status.idle": "2025-08-24T02:42:08.608382Z",
     "shell.execute_reply": "2025-08-24T02:42:08.607695Z"
    },
    "papermill": {
     "duration": 0.008535,
     "end_time": "2025-08-24T02:42:08.609442",
     "exception": false,
     "start_time": "2025-08-24T02:42:08.600907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "classes = trainset.classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb68f29",
   "metadata": {
    "papermill": {
     "duration": 0.003391,
     "end_time": "2025-08-24T02:42:08.616268",
     "exception": false,
     "start_time": "2025-08-24T02:42:08.612877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b948c0f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T02:42:08.623798Z",
     "iopub.status.busy": "2025-08-24T02:42:08.623604Z",
     "iopub.status.idle": "2025-08-24T02:42:11.001830Z",
     "shell.execute_reply": "2025-08-24T02:42:11.001197Z"
    },
    "papermill": {
     "duration": 2.383606,
     "end_time": "2025-08-24T02:42:11.003273",
     "exception": false,
     "start_time": "2025-08-24T02:42:08.619667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
      "100%|██████████| 230M/230M [00:01<00:00, 200MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models \n",
    "# ResNet152\n",
    "resnet = models.resnet152(pretrained = True)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False \n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c14b8a8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T02:42:11.013235Z",
     "iopub.status.busy": "2025-08-24T02:42:11.012754Z",
     "iopub.status.idle": "2025-08-24T02:42:12.833654Z",
     "shell.execute_reply": "2025-08-24T02:42:12.832752Z"
    },
    "papermill": {
     "duration": 1.827123,
     "end_time": "2025-08-24T02:42:12.835036",
     "exception": false,
     "start_time": "2025-08-24T02:42:11.007913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
      "100%|██████████| 233M/233M [00:01<00:00, 216MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models \n",
    "alexnet = models.alexnet(pretrained = True)\n",
    "for param in alexnet.parameters():\n",
    "    param.require_grad = False\n",
    "alexnet.classifier[6] = nn.Linear(alexnet.classifier[6].in_features, len(classes))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09390c61",
   "metadata": {
    "papermill": {
     "duration": 0.004518,
     "end_time": "2025-08-24T02:42:12.844638",
     "exception": false,
     "start_time": "2025-08-24T02:42:12.840120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- param.requires_grad = False\n",
    "\n",
    "In PyTorch, every parameter (weights & biases) has a flag requires_grad.\n",
    "\n",
    "If True → gradients are computed during backpropagation (so it can be updated).\n",
    "\n",
    "If False → parameter is frozen (not updated during training).\n",
    "\n",
    "👉 Why do this?\n",
    "\n",
    "We are doing transfer learning.\n",
    "\n",
    "The pretrained AlexNet already knows useful features (edges, shapes, textures) from ImageNet.\n",
    "\n",
    "We don’t want to “retrain” those millions of parameters (takes too long, needs huge data).\n",
    "\n",
    "So we freeze them by setting requires_grad = False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "374e52f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T02:42:12.855157Z",
     "iopub.status.busy": "2025-08-24T02:42:12.854672Z",
     "iopub.status.idle": "2025-08-24T02:42:12.857847Z",
     "shell.execute_reply": "2025-08-24T02:42:12.857329Z"
    },
    "papermill": {
     "duration": 0.009473,
     "end_time": "2025-08-24T02:42:12.858786",
     "exception": false,
     "start_time": "2025-08-24T02:42:12.849313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 5. Training\n",
    "# ==============================\n",
    "# What happens in each epoch:\n",
    "# - Set model to training mode\n",
    "# - Loop through batches\n",
    "# - Forward pass → get predictions\n",
    "# - Compute loss (CrossEntropy)\n",
    "# - Backward pass → update weights\n",
    "# - Print average loss per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb13274a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T02:42:12.868696Z",
     "iopub.status.busy": "2025-08-24T02:42:12.868516Z",
     "iopub.status.idle": "2025-08-24T02:42:12.873386Z",
     "shell.execute_reply": "2025-08-24T02:42:12.872830Z"
    },
    "papermill": {
     "duration": 0.011082,
     "end_time": "2025-08-24T02:42:12.874439",
     "exception": false,
     "start_time": "2025-08-24T02:42:12.863357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, trainlaoder, epochs = 5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr = 0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images , labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss +=loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d31973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T02:42:12.884869Z",
     "iopub.status.busy": "2025-08-24T02:42:12.884419Z",
     "iopub.status.idle": "2025-08-24T02:42:12.890188Z",
     "shell.execute_reply": "2025-08-24T02:42:12.889527Z"
    },
    "papermill": {
     "duration": 0.012089,
     "end_time": "2025-08-24T02:42:12.891221",
     "exception": false,
     "start_time": "2025-08-24T02:42:12.879132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, testloader, classes):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()  \n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():   # Disable gradient calculation\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)       # Forward pass\n",
    "            _, preds = torch.max(outputs, 1)  # Get class with max probability\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=classes))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a8abaea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-24T02:42:12.901181Z",
     "iopub.status.busy": "2025-08-24T02:42:12.900957Z",
     "iopub.status.idle": "2025-08-24T03:33:27.663821Z",
     "shell.execute_reply": "2025-08-24T03:33:27.663033Z"
    },
    "papermill": {
     "duration": 3074.769101,
     "end_time": "2025-08-24T03:33:27.665011",
     "exception": false,
     "start_time": "2025-08-24T02:42:12.895910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet152...\n",
      "Epoch [1/5], Loss: 0.6698\n",
      "Epoch [2/5], Loss: 0.5508\n",
      "Epoch [3/5], Loss: 0.5356\n",
      "Epoch [4/5], Loss: 0.5090\n",
      "Epoch [5/5], Loss: 0.5044\n",
      "\n",
      "Evaluating ResNet152...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.85      0.84      0.85      1000\n",
      "  automobile       0.84      0.95      0.89      1000\n",
      "        bird       0.72      0.86      0.79      1000\n",
      "         cat       0.75      0.73      0.74      1000\n",
      "        deer       0.84      0.80      0.82      1000\n",
      "         dog       0.85      0.79      0.82      1000\n",
      "        frog       0.95      0.85      0.90      1000\n",
      "       horse       0.84      0.88      0.86      1000\n",
      "        ship       0.90      0.88      0.89      1000\n",
      "       truck       0.93      0.85      0.89      1000\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.85      0.84      0.84     10000\n",
      "weighted avg       0.85      0.84      0.84     10000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[840  26  39   7   8   0   0  13  57  10]\n",
      " [  2 948   2   5   0   1   0   3   9  30]\n",
      " [ 25   4 862  26  39   9  11  17   5   2]\n",
      " [ 10  11  90 727  33  80   9  26   8   6]\n",
      " [ 11   1  69  23 797   8  19  64   6   2]\n",
      " [  4   3  37 105  15 792   4  35   2   3]\n",
      " [  3   7  60  41  21  12 850   3   0   3]\n",
      " [  7   6  24  23  34  22   2 878   2   2]\n",
      " [ 65  25  11   5   1   2   0   2 878  11]\n",
      " [ 17 102   2   5   1   1   1   6  13 852]]\n",
      "\n",
      "Training AlexNet...\n",
      "Epoch [1/5], Loss: 2.3046\n",
      "Epoch [2/5], Loss: 2.3033\n",
      "Epoch [3/5], Loss: 2.3032\n",
      "Epoch [4/5], Loss: 2.3033\n",
      "Epoch [5/5], Loss: 2.3032\n",
      "\n",
      "Evaluating AlexNet...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.00      0.00      0.00      1000\n",
      "  automobile       0.00      0.00      0.00      1000\n",
      "        bird       0.10      1.00      0.18      1000\n",
      "         cat       0.00      0.00      0.00      1000\n",
      "        deer       0.00      0.00      0.00      1000\n",
      "         dog       0.00      0.00      0.00      1000\n",
      "        frog       0.00      0.00      0.00      1000\n",
      "       horse       0.00      0.00      0.00      1000\n",
      "        ship       0.00      0.00      0.00      1000\n",
      "       truck       0.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.10     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.10      0.02     10000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]\n",
      " [   0    0 1000    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining ResNet152...\")\n",
    "resnet_trained = train(resnet, trainloader, epochs=5)\n",
    "print(\"\\nEvaluating ResNet152...\")\n",
    "evaluate_model(resnet_trained, testloader, classes)\n",
    "\n",
    "# Train & Evaluate AlexNet\n",
    "print(\"\\nTraining AlexNet...\")\n",
    "alexnet_trained = train(alexnet, trainloader, epochs=5)\n",
    "print(\"\\nEvaluating AlexNet...\")\n",
    "evaluate_model(alexnet_trained, testloader, classes)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3108.166823,
   "end_time": "2025-08-24T03:33:31.305619",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-24T02:41:43.138796",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
